{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-3 : 모델 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 참값 데이타를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.77636042e-02   9.68038023e-01   3.06955744e-02   1.47216499e-01\n",
      "   9.33517003e-04   5.18431425e-01   8.30147684e-01   1.17437251e-01\n",
      "   2.90193707e-01   5.65207362e-01   7.92811573e-01   1.10972025e-01\n",
      "   5.42888977e-02   9.63820636e-01   2.80752480e-01   2.85820454e-01\n",
      "   7.17859209e-01   3.62922817e-01   4.08129305e-01   6.89597905e-01\n",
      "   3.54913212e-02   4.09568287e-02   7.26809859e-01   8.64227891e-01\n",
      "   5.82166195e-01   8.32873046e-01   5.30579165e-02   5.45904934e-01\n",
      "   9.56791401e-01   1.87967986e-01   6.89753294e-01   5.98635912e-01\n",
      "   2.60724783e-01   5.97906053e-01   6.96163416e-01   2.60451198e-01\n",
      "   6.41551912e-01   8.45582187e-01   1.42486125e-01   4.17219132e-01\n",
      "   8.90343785e-01   6.41240418e-01   9.56185341e-01   4.86112446e-01\n",
      "   6.07389987e-01   4.79750365e-01   3.43626857e-01   7.83774018e-01\n",
      "   6.19254470e-01   4.44736749e-01   5.76064765e-01   7.44381070e-01\n",
      "   8.76927555e-01   9.73196387e-01   3.74731153e-01   7.39400685e-01\n",
      "   6.08138800e-01   8.57853591e-01   1.99671090e-01   5.84062114e-02\n",
      "   3.37667793e-01   3.83750468e-01   1.91786692e-01   5.21476150e-01\n",
      "   4.68629152e-01   5.14895797e-01   4.49089020e-01   1.22819118e-01\n",
      "   9.04631376e-01   7.57966518e-01   8.88945937e-01   2.51953661e-01\n",
      "   7.18834817e-01   3.89016747e-01   6.85943961e-01   4.37376946e-01\n",
      "   3.32005173e-01   7.00129867e-01   9.20153737e-01   1.11723274e-01\n",
      "   5.50827920e-01   4.15401280e-01   4.41688113e-02   6.00481629e-01\n",
      "   6.98754549e-01   6.05262578e-01   6.74990416e-02   3.31524640e-01\n",
      "   5.99131361e-02   6.60832942e-01   8.39624166e-01   2.23563150e-01\n",
      "   2.86416799e-01   8.57363045e-01   2.17687666e-01   5.11664391e-01\n",
      "   6.81693852e-01   8.93441260e-01   8.72407794e-01   7.60128140e-01]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.float32(np.random.rand(100))  # 100개의 랜덤값을 만들기\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13552725  2.93607616  1.06139112  1.294433    1.00186706  2.03686285\n",
      "  2.66029549  1.23487449  1.58038735  2.13041472  2.58562326  1.22194409\n",
      "  1.10857785  2.92764139  1.56150496  1.57164097  2.43571854  1.72584558\n",
      "  1.81625867  2.37919569  1.07098269  1.08191371  2.45361972  2.72845578\n",
      "  2.16433239  2.66574621  1.10611582  2.09180975  2.9135828   1.37593603\n",
      "  2.37950659  2.19727182  1.52144957  2.19581223  2.39232683  1.5209024\n",
      "  2.28310394  2.69116449  1.28497219  1.83443832  2.78068757  2.28248072\n",
      "  2.91237068  1.97222495  2.21477985  1.95950079  1.68725371  2.56754804\n",
      "  2.23850894  1.88947344  2.15212965  2.48876214  2.75385523  2.94639277\n",
      "  1.74946237  2.47880125  2.2162776   2.7157073   1.39934218  1.11681247\n",
      "  1.67533565  1.76750088  1.38357341  2.0429523   1.93725824  2.02979159\n",
      "  1.8981781   1.24563825  2.80926275  2.51593304  2.77789187  1.50390732\n",
      "  2.43766975  1.77803349  2.37188792  1.87475395  1.66401029  2.40025973\n",
      "  2.84030747  1.22344661  2.10165596  1.83080256  1.08833766  2.20096326\n",
      "  2.3975091   2.21052504  1.13499808  1.66304922  1.11982632  2.32166576\n",
      "  2.67924833  1.44712627  1.57283354  2.71472597  1.43537533  2.02332878\n",
      "  2.36338758  2.7868824   2.74481559  2.52025628]\n"
     ]
    }
   ],
   "source": [
    "y_data = 2 * x_data + 1    # y = 2 * x + 1 의 모델에 의해 y값을 만들기\n",
    "                           # 나중에 찾고자 하는 파라미터는 2와 1이다. \n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b는 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W는 1x2 형태의 웨이트 변수 (균등 랜덤값으로 초기화)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# W를 x_data랑 곱하고  b를 더하기 \n",
    "y = W * x_data + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의 (define loss function)\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# 경사하강법으로 손실 함수를 최소화 (0.5는 학습 비율) \n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# loss를 최소화하는 W와 b를 찾는 학습 오퍼레이션을 정의\n",
    "# set the train operator which finds W and b which minimize loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.75731158] [ 2.31167841]\n",
      "20 [ 1.64430416] [ 1.19080019]\n",
      "40 [ 1.91629004] [ 1.04490328]\n",
      "60 [ 1.98029959] [ 1.01056755]\n",
      "80 [ 1.99536359] [ 1.00248706]\n",
      "100 [ 1.99890888] [ 1.00058532]\n",
      "120 [ 1.99974322] [ 1.00013781]\n",
      "140 [ 1.99993968] [ 1.00003231]\n",
      "160 [ 1.99998581] [ 1.00000763]\n",
      "180 [ 1.99999654] [ 1.00000179]\n"
     ]
    }
   ],
   "source": [
    "# 모든 변수를 초기화하는 오퍼레이션 정의 (operation which initializes all variables)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 세션 시작 (start session)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 200번 학습. 200번 train operation을 실행하기 (iterate 200 times the train operation)\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 복잡한 예제: \n",
    "https://gist.github.com/haje01/202ac276bace4b25dd3f 의 예제를 가지고 옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Numpy 랜덤으로 100개의 2-D 데이터 채우기. (float64 -> float32로 변환)\n",
    "x_data = np.float32(np.random.rand(2, 100))\n",
    "\n",
    "# 학습 레이블(목표값)의 참값을 (W_true = [0.1, 0.2], b_true = 0.3)으로 주고\n",
    "# 이 레이블을 사용하여 x_data에 대응되는 y_data를 생성함.\n",
    "#  W_true = [0.1, 0.2], b_true = 0.3는 우리가 찾고자 하는 파라미터임.\n",
    "\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b는 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W는 1x2 형태의 웨이트 변수 (균등 랜덤값으로 초기화)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "\n",
    "# W를 x_data랑 곱하고  b를 더하기 \n",
    "\n",
    "y = tf.matmul(W, x_data) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 정의 및 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의 (define loss function)\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# 경사하강법으로 손실 함수를 최소화 (0.5는 학습 비율) \n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# loss를 최소화하는 W와 b를 찾는 학습 오퍼레이션을 정의\n",
    "# set the train operator which finds W and b which minimize loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.881657   -0.31105733]] [ 0.33505285]\n",
      "20 [[ 0.24901     0.14225051]] [ 0.25259653]\n",
      "40 [[ 0.13863526  0.20323031]] [ 0.2782447]\n",
      "60 [[ 0.11241937  0.20544076]] [ 0.29071784]\n",
      "80 [[ 0.1045731   0.20286217]] [ 0.2961356]\n",
      "100 [[ 0.10179723  0.20127107]] [ 0.29840526]\n",
      "120 [[ 0.10072563  0.20053652]] [ 0.299344]\n",
      "140 [[ 0.10029603  0.20022249]] [ 0.29973051]\n",
      "160 [[ 0.10012123  0.20009169]] [ 0.29988933]\n",
      "180 [[ 0.10004971  0.20003769]] [ 0.29995456]\n"
     ]
    }
   ],
   "source": [
    "# 모든 변수를 초기화하는 오퍼레이션 정의 (operation which initializes all variables)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 세션 시작 (start session)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 200번 학습. 200번 train operation을 실행하기 (iterate 200 times the train operation)\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
